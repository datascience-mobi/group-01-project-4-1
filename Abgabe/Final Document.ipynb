{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import warnings\n",
    "from copy import deepcopy\n",
    "import timeit\n",
    "from random import choice\n",
    "import time\n",
    "\n",
    "from sklearn import cluster, datasets, mixture\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "from itertools import cycle, islice\n",
    "from itertools import cycle, islice\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "# distance calculator\n",
    "\n",
    "def dist(a, b, ax=1):\n",
    "    return np.linalg.norm(a - b, axis=ax)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gliederung\n",
    "1. Generation of different datasets\n",
    "2. Kmeans Algorithm\n",
    "3. Kmeans++\n",
    "4. Minibatch kmeans\n",
    "5. Vergleich own implementation with sctilearn implementation\n",
    "6. eigene Implementation auf unseren Dateset anwenden\n",
    "7. Markergenes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Generation of different datasets\n",
    "\n",
    "we generated different datasets to test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples=1000 #Size of Dataset, variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noisy Circles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_circles = datasets.make_circles(n_samples=n_samples, factor=.5,noise=.05)\n",
    "points_noisy_circles=noisy_circles[0]\n",
    "\n",
    "f1=points_noisy_circles[0:((n_samples)), 0]\n",
    "f2=points_noisy_circles[0:((n_samples)),1]\n",
    "\n",
    "plt.scatter(f1, f2, c='black', s=7)\n",
    "plt.title('Noisy circle')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noisy moons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_moons = datasets.make_moons(n_samples=n_samples, noise=.05)\n",
    "points_noisy_moons=noisy_moons[0]\n",
    "f1=points_noisy_moons[0:((n_samples)), 0]\n",
    "f2=points_noisy_moons[0:((n_samples)),1]\n",
    "plt.scatter(f1, f2, c='black', s=7)\n",
    "plt.title('Noisy moons')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_structure = np.random.rand(n_samples, 2)\n",
    "f1=no_structure[0:((n_samples)), 0]\n",
    "f2=no_structure[0:((n_samples)),1]\n",
    "\n",
    "plt.title('No structure')\n",
    "plt.scatter(f1, f2, c='black', s=7) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blobs = datasets.make_blobs(n_samples=n_samples, random_state=15)\n",
    "points_blobs=blobs[0]\n",
    "\n",
    "f1=points_blobs[0:((n_samples)), 0]\n",
    "f2=points_blobs[0:((n_samples)),1]\n",
    "\n",
    "plt.scatter(f1, f2, c='black', s=7)\n",
    "plt.title('Blobs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in diesem dokument haben wir repräsatativ die blobs ausgewählt da es am meisten mach den zu clustern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(list(zip(f1, f2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Kmeans Implementation -> Lloyd-Algorithmus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pseudo code\n",
    "1. Initialization: Choose initial centroids -> choose k samples from the dataset X\n",
    "\n",
    "    \n",
    "    Looping between the following steps:\n",
    "\n",
    "\n",
    "2. Assignment: Each sample is assigned to its nearest center\n",
    "\n",
    "3. Update the centroids: calculate the mean values of all of the samples assigned to each previous centroid.\n",
    "\n",
    "   the algorithm repeats these last two steps until there is no difference between the old and the new centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initialization\n",
    "\n",
    "1. chossing number of clusers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. In order to avoid that no datapoints will be assigned to the initial centroids, we choose some random samples from our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Indecies_centroid = np.random.choice(n_samples,size=k) # for initialization we choose some random datapoint in order to avoid that no data points were assigned to random centroid\n",
    "    \n",
    "      \n",
    "C=X[Indecies_centroid]\n",
    "\n",
    "plt.scatter(f1,f2,c='black',s=7)\n",
    "plt.scatter(C[:, 0], C[:, 1],marker='*',c='red',s=100)\n",
    "plt.title('Blobs with random centers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Distanzen von jedem Sample zu allen Clustern berechnen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(X)):\n",
    "            distances = dist(C,[X[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Minimale Distanz auswählen -> Zuordnung zu diesem Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = np.zeros(len(X)) ## Hier genieren wir einen leeren Array, der dann überschrieben wird in for loop\n",
    "\n",
    "\n",
    "for i in range(len(X)):\n",
    "            distances = dist(C,[X[i]])\n",
    "            cluster = np.argmin(distances)\n",
    "            clusters[i] = cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate the mean values of all of the samples assigned to each previous centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "for i in range(k):\n",
    "        points = [X[j] for j in range(len(X)) if clusters[j] == i]\n",
    "        C[i] = np.mean(points, axis=0)\n",
    "        \n",
    "print(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "die letzten zwei Schritte (Assignment und update) so lange wiederholen, bis sich Centroide nicht mehr verändern. daher keine Distanz von C_old zu C (new) \n",
    "\n",
    "-> Schlaufe um diese Schritte legen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = np.zeros(len(X))\n",
    "C_old = np.zeros(C.shape)\n",
    "update_centroids = dist(C, C_old) # Konvergenz\n",
    "\n",
    "while update_centroids.all() != 0:\n",
    "    for i in range(len(X)):\n",
    "            distances = dist(C,[X[i]])\n",
    "            cluster = np.argmin(distances)\n",
    "            clusters[i] = cluster\n",
    "    C_old = deepcopy(C) # der alte Wert muss zwischengespeichert werden, damit Veränderung von C_od zu C (new) berrechnet werden kann\n",
    "    for i in range(k):\n",
    "        points = [X[j] for j in range(len(X)) if clusters[j] == i]\n",
    "        C[i] = np.mean(points, axis=0)\n",
    "    update_centroids = dist(C, C_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "for i in range(k):\n",
    "        points = np.array([X[j] for j in range(len(X)) if clusters[j] == i])\n",
    "        ax.scatter(points[:, 0], points[:, 1], s=7)\n",
    "ax.scatter(C[:, 0], C[:, 1], marker='*', c='black', s=100)\n",
    "plt.title('Blobs clustered with kmeans')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-means ++\n",
    "\n",
    "   1. Take one center c1, chosen uniformly at random X\n",
    "   2. Take an new center ci, choosing x e X with probability Dx^2/(summe Dx^2)\n",
    "   3. Repeat step 2 until we have taken k centers altogether\n",
    "   4. Proceed as with the standard k-means algorthm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1\n",
    "\n",
    "Take one center c1, chosen uniformly at random from X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C2 = np.random.random((1,2))\n",
    "print(C2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 and 3:\n",
    "\n",
    "Take a new center ci choosing xEX with probability (D(x)^2)/(Summe D(x)^2)\n",
    "\n",
    "D(x) denote the shortest distance from a data point to the closest center we have already chosen\n",
    "\n",
    "Choose one new data point at random as a new center, using a weighted probability distribution where a point x is chosen with probability proportional to D(x)2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distance calculator\n",
    "\n",
    "def dist(a, b, ax=1):\n",
    "    return np.linalg.norm(a - b, axis=ax)\n",
    "\n",
    "#\"Kmeans part\"    \n",
    "clusters = np.zeros(len(X))\n",
    "C_old = np.zeros(C2.shape)\n",
    "error = dist(C2, C_old) # Konvergenz\n",
    "\n",
    "#\"Kmeans++ part\"\n",
    "data_2 = pd.DataFrame(X)\n",
    "data_long = data_2.reset_index().melt(id_vars=\"index\") #Index aus Wahrscheinlichkeitsverteilung zur Tabelle hinzufügen\n",
    "a = np.array(data_long)\n",
    "index =a[0:n_samples,0] #Index definieren\n",
    "Liste =[] #Liste für kleinsten Distanzen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(C2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=3#Anzahl der Cluster festlegen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=0\n",
    "\n",
    "while n < k - 1:\n",
    "    n=n+1\n",
    "    Liste =[]\n",
    "    for i in range (len(X)):\n",
    "        diff=X[i]-C2\n",
    "        dist = np.linalg.norm(diff,axis=1) # Distance berechnen\n",
    "        min_dist= np.min(dist)\n",
    "        Liste.append(min_dist)\n",
    "    s= np.array(Liste)\n",
    "    dist_2 = (s)**2\n",
    "    prob = (dist_2)/ sum (dist_2) #p-Verteilung\n",
    "    z=np.random.choice(index, p=prob) #Index des neuen Clusters in Tabelle\n",
    "    c_neu=X[z] #Datenpunkt mit Index z als neues Center festlegen\n",
    "    cl = np.ndarray.tolist(C2) #alter arry in liste umwandeln damit ein Wert hinzugefügt werden kann\n",
    "    c_neul = np.ndarray.tolist (c_neu) #neuer Wert in Liste umgewandelt\n",
    "    cl.append (c_neul) # Center-Liste mit neuen Centerdaten erweitern\n",
    "    C2 = np.array(cl) #Liste wieder in Array umwandeln\n",
    "print(C2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cx1= C2[0:((k)),0]\n",
    "cy1 = C2[0:((k)),1]\n",
    "\n",
    "plt.scatter(f1,f2,c='black',s=7)\n",
    "\n",
    "plt.scatter(cx1,cy1,marker='*',c='red',s=100)\n",
    "plt.title('Blobs with centers defined by kmeans++ algorithm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4\n",
    "\n",
    "Proceed as with the standard k-means algorthm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while error.all() != 0:\n",
    "    for i in range(len(X)):\n",
    "            diff2=X[i]-C2\n",
    "            distances = np.linalg.norm(diff2,axis=1) # Distance berechnen\n",
    "            cluster = np.argmin(distances)\n",
    "            clusters[i] = cluster\n",
    "    C_old = deepcopy(C2)\n",
    "    for i in range(k):\n",
    "        points = [X[j] for j in range(len(X)) if clusters[j] == i]\n",
    "        C2[i] = np.mean(points, axis=0)\n",
    "    diff3 = C2-C_old\n",
    "    error = np.linalg.norm(diff3,axis=1) # Distance berechnen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['r', 'g', 'b', 'y', 'c', 'm']\n",
    "fig, ax = plt.subplots()\n",
    "for i in range(k):\n",
    "        points = np.array([X[j] for j in range(len(X)) if clusters[j] == i])\n",
    "        ax.scatter(points[:, 0], points[:, 1], s=7, c=colors[i])\n",
    "plt.scatter(cx1,cy1,marker='*',c='red',s=100)\n",
    "plt.title('Blobs clustered with kmeans++')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini-batch implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vergleich"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scitlearn implementations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Kmeans**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=3).fit_predict(X)\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], c=kmeans,s=7)\n",
    "plt.title('Blobs clustered wiht scitlearn kmeans')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Kmeans++**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=3,init='k-means++').fit_predict(X)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=kmeans,s=7)\n",
    "plt.title('Blobs clustered with scitlearn kmeans++')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Minibatch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = MiniBatchKMeans(n_clusters=k, \n",
    "                         random_state=0, \n",
    "                         batch_size=10,\n",
    "                        max_iter=4).fit(X)\n",
    "c3 = kmeans.cluster_centers_[0, :]\n",
    "c4 = kmeans.cluster_centers_[1, :]\n",
    "\n",
    "plt.scatter(f1, f2, c='green', s=15)\n",
    "\n",
    "X = (list(zip(f1, f2)))\n",
    "\n",
    "plt.scatter(c3, c4, marker='*',c='red',s=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "den vergleich haben wir jetzt nur repräsentativ für kmeans mit scitlearn gemacht"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Qualtity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distance calculator\n",
    "\n",
    "def dist(a, b, ax=1):\n",
    "    return np.linalg.norm(a - b, axis=ax)\n",
    "X = np.array(list(zip(f1, f2)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Own implementation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_all=(2,3,5,10) # hier kann man die Anzahl an k, die man vergleichen will, einfach eingeben\n",
    "\n",
    "WSS_own = np.zeros(4)\n",
    "\n",
    "for l in range(4):\n",
    "    k=k_all[l]\n",
    "    \n",
    "    times_to_repeat = 10\n",
    "\n",
    "    sum_WSS = 0\n",
    "    \n",
    "    \n",
    "    for j in range (times_to_repeat):\n",
    "\n",
    "\n",
    "        start_time = timeit.default_timer()\n",
    "\n",
    "\n",
    "        Indecies_centroid = np.random.choice(n_samples,size=k) # for initialization we choose some random datapoint in order to avoid that no data points were assigned to random centroid\n",
    "\n",
    "\n",
    "        C=X[Indecies_centroid]\n",
    "\n",
    "        clusters = np.zeros(len(X))\n",
    "        C_old = np.zeros(C.shape)\n",
    "        error = dist(C, C_old) # Konvergenz\n",
    "        from copy import deepcopy\n",
    "\n",
    "        while error.all() != 0:\n",
    "            for i in range(len(X)):\n",
    "                    distances = dist(C,[X[i]])\n",
    "                    cluster = np.argmin(distances)\n",
    "                    clusters[i] = cluster\n",
    "            C_old = deepcopy(C)\n",
    "            for i in range(k):\n",
    "                points = [X[j] for j in range(len(X)) if clusters[j] == i]\n",
    "                C[i] = np.mean(points, axis=0)\n",
    "            error = dist(C, C_old)\n",
    "\n",
    "\n",
    "        \n",
    "        WSS=0\n",
    "\n",
    "        for j in range(len(X)):\n",
    "        \n",
    "            WSS += dist(X[j],C[int(clusters[j])], ax = 0)**2\n",
    "  \n",
    "        sum_WSS=sum_WSS+WSS\n",
    "    \n",
    "    average_WSS= (sum_WSS/times_to_repeat)\n",
    "    \n",
    "      \n",
    "    \n",
    "    WSS_own[l]=average_WSS\n",
    "   \n",
    "    print(WSS_own)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Scitlearn implementation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters=(2,3,5,10)\n",
    "\n",
    "WSS_scikit = np.zeros(4)\n",
    "\n",
    "for l in range(4):\n",
    "\n",
    "    times_to_repeat = 10\n",
    "\n",
    "    sum_WSS = 0\n",
    "\n",
    "    for i in range (times_to_repeat):\n",
    "        \n",
    "        \n",
    "\n",
    "        start_time = timeit.default_timer()\n",
    "\n",
    "        kmeans = KMeans(n_clusters[l])\n",
    "\n",
    "\n",
    "        a = kmeans.fit_predict(X)\n",
    "        kmeans.inertia_\n",
    "       \n",
    "        \n",
    "        sum_WSS=sum_WSS+kmeans.inertia_\n",
    "    \n",
    "        average_WSS= sum_WSS/times_to_repeat\n",
    "    \n",
    "        WSS_scikit[l]=average_WSS\n",
    "\n",
    "\n",
    "print(WSS_scikit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Plot*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## hab hier alles so angepasst, dass Beschriftungen alle automatisch passen, je nach dem wie man n_samples, k etc verändert hat\n",
    "\n",
    "# data to plot\n",
    "n_groups = 4\n",
    "means_own = (WSS_own)\n",
    "means_scikit = (WSS_scikit)\n",
    "\n",
    "# create plot\n",
    "fig, ax = plt.subplots()\n",
    "index = np.arange(n_groups)\n",
    "bar_width = 0.35\n",
    "opacity = 0.8\n",
    "\n",
    "rects1 = plt.bar(index, means_own, bar_width,\n",
    "alpha=opacity,\n",
    "color='b',\n",
    "label='own implementation')\n",
    "\n",
    "rects2 = plt.bar(index + bar_width, means_scikit, bar_width,\n",
    "alpha=opacity,\n",
    "color='g',\n",
    "label='Scikit learn implementation')\n",
    "\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('average sum of squared distances within all clusters')\n",
    "plt.title('quality comparison, blobs , n=' +  str(n_samples))\n",
    "plt.xticks(index + bar_width, (k_all))\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist(a, b, ax=1):\n",
    "    return np.linalg.norm(a - b, axis=ax)\n",
    "X = np.array(list(zip(f1, f2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Own implementation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_all=(2,3,5,10) # hier kann man die Anzahl an k, die man vergleichen will, einfach eingeben\n",
    "\n",
    "runtime_own = np.zeros(4)\n",
    "\n",
    "for l in range(4):\n",
    "    k=k_all[l]\n",
    "    \n",
    "    times_to_repeat = 10\n",
    "\n",
    "    sum_runtime = 0\n",
    "    \n",
    "    \n",
    "    for j in range (times_to_repeat):\n",
    "\n",
    "\n",
    "        start_time = timeit.default_timer()\n",
    "\n",
    "\n",
    "        Indecies_centroid = np.random.choice(n_samples,size=k) # for initialization we choose some random datapoint in order to avoid that no data points were assigned to random centroid\n",
    "\n",
    "\n",
    "        C=X[Indecies_centroid]\n",
    "\n",
    "        clusters = np.zeros(len(X))\n",
    "        C_old = np.zeros(C.shape)\n",
    "        error = dist(C, C_old) # Konvergenz\n",
    "        from copy import deepcopy\n",
    "\n",
    "        while error.all() != 0:\n",
    "            for i in range(len(X)):\n",
    "                    distances = dist(C,[X[i]])\n",
    "                    cluster = np.argmin(distances)\n",
    "                    clusters[i] = cluster\n",
    "            C_old = deepcopy(C)\n",
    "            for i in range(k):\n",
    "                points = [X[j] for j in range(len(X)) if clusters[j] == i]\n",
    "                C[i] = np.mean(points, axis=0)\n",
    "            error = dist(C, C_old)\n",
    "\n",
    "\n",
    "        \n",
    "        runtime= timeit.default_timer() - start_time\n",
    "    \n",
    "        sum_runtime= sum_runtime+runtime\n",
    "  \n",
    "\n",
    "    average_runtime= (sum_runtime/times_to_repeat)\n",
    "    \n",
    "    \n",
    "    runtime_own[l]=average_runtime\n",
    "   \n",
    "    print(runtime_own)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Scitlearn implementation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters=(2,3,5,10)\n",
    "\n",
    "runtime_scikit = np.zeros(4)\n",
    "\n",
    "for l in range(4):\n",
    "    \n",
    "\n",
    "    times_to_repeat = 10\n",
    "\n",
    "    sum_runtime = 0\n",
    "\n",
    "    for i in range (times_to_repeat):\n",
    "\n",
    "\n",
    "        start_time = timeit.default_timer()\n",
    "\n",
    "        kmeans = KMeans(n_clusters[l]).fit_predict(X)\n",
    "\n",
    "\n",
    "        runtime= timeit.default_timer() - start_time\n",
    "    \n",
    "        sum_runtime= sum_runtime+runtime\n",
    "    \n",
    "    average_runtime= sum_runtime/times_to_repeat\n",
    "    \n",
    "    runtime_scikit[l]=average_runtime\n",
    "   \n",
    "\n",
    "print(runtime_scikit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Plot*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data to plot\n",
    "n_groups = 4\n",
    "means_own = (runtime_own)\n",
    "means_scikit = (runtime_scikit)\n",
    "\n",
    "# create plot\n",
    "fig, ax = plt.subplots()\n",
    "index = np.arange(n_groups)\n",
    "bar_width = 0.35\n",
    "opacity = 0.8\n",
    "\n",
    "rects1 = plt.bar(index, means_own, bar_width,\n",
    "alpha=opacity,\n",
    "color='b',\n",
    "label='own implementation')\n",
    "\n",
    "rects2 = plt.bar(index + bar_width, means_scikit, bar_width,\n",
    "alpha=opacity,\n",
    "color='g',\n",
    "label='Scikit learn implementation')\n",
    "\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('average runtime')\n",
    "plt.title('runtime comparison, blobs , n=' +  str(n_samples))\n",
    "plt.xticks(index + bar_width, (k_all))\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
